{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_lstm_real",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dislu/Machine_Learning/blob/main/conv_lstm_real.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlL4kz_HOF5X"
      },
      "source": [
        "# Next-frame prediction with Conv-LSTM\n",
        "\n",
        "**Author:** [Arvind Singh](https://github.com/jeammimi)<br>\n",
        "**Date created:** 2021/04/07<br>\n",
        "**Last modified:** 2021/04/08<br>\n",
        "**Description:** Predict the next frame in a sequence using a Conv-LSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3R_FxxSOF5b"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This script demonstrates the use of a convolutional LSTM model.\n",
        "The model is used to predict the next frame of a movie generated from sst daily mean image dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOW4TZKAOF5b"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqaP4yWGOF5b"
      },
      "source": [
        "from google.colab import drive\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling3D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from keras.models import model_from_json \n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "n_samples =12000 # total Number of movie samples \n",
        "n_frames = 20    # Number of frames in a movie\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmpXsPCcOF5c"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We create a model which take as input movies of shape\n",
        "`(n_frames, width, height, channels)` and returns a movie\n",
        "of identical shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhfg05l8OF5c"
      },
      "source": [
        "seq = Sequential()\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                  input_shape=(None, 60, 48, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "#seq.add(MaxPooling3D(pool_size = (1,2,2),padding = 'same'))\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "#seq.add(MaxPooling3D(pool_size = (1,2,2),padding = 'same'))\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "#seq.add(MaxPooling3D(pool_size = (1,2,2), padding = 'same'))\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "#seq.add(MaxPooling3D(pool_size = (1,2,2), padding = 'same'))\n",
        "\n",
        "seq.add(Conv3D(filters=3, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9yXzQftOF5c"
      },
      "source": [
        "## Generate data for movie\n",
        "\n",
        "Generate movies with 20 days daily mean images of SST inside.\n",
        "The squares are of shape 1x1 or 2x2 pixels,\n",
        "and move linearly over time.\n",
        "For convenience, we first create movies with bigger width and height (80x80)\n",
        "and at the end we select a 40x40 window.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2x6Y6ErOF5d"
      },
      "source": [
        "\n",
        "def generate_movies(n_samples, n_frames):\n",
        "    folder = '/content/drive/My Drive/Colab_Notebooks/sst.day.mean.1981-2019.Figures/'\n",
        "    images = sorted(os.listdir(folder))\n",
        "    input_movie=[]\n",
        "    label_movie=[]\n",
        "    movie_array_input = []\n",
        "    movie_array_label = []\n",
        "    for sample in range(n_samples):\n",
        "        for frame in range(sample,sample+n_frames):\n",
        "            # reading images for input data and labels\n",
        "            im_i = Image.open(folder + images[sample])\n",
        "            im_l = Image.open(folder + images[sample+1])\n",
        "            \n",
        "            #im_i = im_i.getdata()\n",
        "            #im_l = im_l.getdata()\n",
        "            # converting images into nparray and append\n",
        "            movie_array_input.append(np.array(im_i)) #.transpose(1, 0, 2))\n",
        "            movie_array_label.append(np.array(im_l))\n",
        "            # converting list of image array to array \n",
        "        movie_array_input = np.array(movie_array_input)\n",
        "        movie_array_label = np.array(movie_array_label)\n",
        "\n",
        "        input_movie.append(movie_array_input)\n",
        "        label_movie.append(movie_array_label) \n",
        "        movie_array_input = []\n",
        "        movie_array_label = []\n",
        "    input_movie = np.array(input_movie)\n",
        "    label_movie = np.array(label_movie)\n",
        "    print(input_movie.shape)\n",
        "    print(label_movie.shape)\n",
        "    #(75, 50, 100, 3)\n",
        "    return input_movie, label_movie\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIAxNsibOF5d"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H21RncNiOF5d"
      },
      "source": [
        "noisy_movies, shifted_movies = generate_movies(n_samples, n_frames)\n",
        "seq.fit(\n",
        "    noisy_movies[:int(0.8*n_samples)],\n",
        "    shifted_movies[:int(0.8*n_samples)],\n",
        "    batch_size=128,\n",
        "    epochs=300,\n",
        "    validation_split=0.33\n",
        "    )\n",
        "\n",
        "# save model\n",
        "# serialize model to JSON\n",
        "#model_json = seq.to_json()\n",
        "#with open(\"seq.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "#seq.save_weights(\"model.h5\")\n",
        "#print(\"Saved model to disk\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCobD9GLOF5e"
      },
      "source": [
        "## Test the model on one movie\n",
        "\n",
        "Feed it with the first 7 positions and then\n",
        "predict the new positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RvJJleMOF5e"
      },
      "source": [
        "which = int(0.8*n_samples+10)\n",
        "track = noisy_movies[which][:int(n_frames/2), ::, ::, ::]\n",
        "\n",
        "for j in range(n_frames+1):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "\n",
        "# And then compare the predictions\n",
        "# to the ground truth\n",
        "track2 = noisy_movies[which][::, ::, ::, ::]\n",
        "for i in range(n_frames):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= int(n_frames/2):\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig('%i_sst_field.png' % (i + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}